---
title: 'OpenStack 구축기 #3: Manual Install 과정'
date: '2025-09-30'
tags: [OpenStack, Build, Installation]
draft: false
summary: OpenStack Epoxy(2025.1) 버전을 수동 설치하는 과정을 정리한 글
---

<img className="inline" src="/static/images/Blog/proxmox.png" />
이제부터 설명할 OpenStack 수동 설치 과정은 OpenInfra KOREA USER GROUP 게시판에 올라온 [OpenStack 입문자
자료](https://smsolutions.slab.com/public/posts/ogjs-104-%EC%B9%9C%EC%A0%88%ED%95%9C-%EA%B9%80%EC%84%A0%EC%9E%84-5r4edxq3?shr=gm6365tt31kxen7dc4d530u0)를
기반으로 한다.

해당 메뉴얼의 part 01을 보면 물리적인 환경을 구성하는 과정이 나오는데, 나는 친구가 제공해준 서버 환경에 구축하려 하기에 장비 세팅 과정은 넘겼다.

나의 기본 세팅 환경은 다음과 같다. Storage 노드만 Cinder의 LVM 구성을 위해 512GB 디스크를 더 추가했다.

- Controller : CPU 8 Core, RAM 8GB, Disk 128GB
- Compute : CPU 8 Core, RAM 8GB, Disk 128GB
- Network : CPU 8 Core, RAM 8GB, Disk 128GB
- Storage : CPU 8 Core, RAM 8GB, <u>Disk 640GB</u>

Netplan은 다음과 같이 구성했다.  
**[Controller, Storage 노드 구성]**

```yaml
network:
    version: 2
    ethernets:
        enp6s18:
            dhcp4: false
            addresses:
                - node_ip_addr/24
            routes:
                - to: default
                via: gateway_addr
            nameservers:
                addresses: [1.1.1.1, 8.8.8.8]
```

**[Network, Storage 노드 구성]**

```yaml
network:
    version: 2
    ethernets:
        enp6s18:
            dhcp4: false
    bridges:
        br-ex:
            openvswitch: {}
            interfaces: [enp6s18]
            dhcp4: false
            addresses:
                - node_ip_addr/24
            routes:
                - to: default
                via: gateway_addr
            nameservers:
                addresses: [1.1.1.1, 8.8.8.8]
```

이후부터는 [메뉴얼 4.5](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-04-1r4p3yac?shr=8zhpgj1f3a24pu31rsv6dbhc#hd3lm-4-5-hostname-%EC%84%A4%EC%A0%95)부터 동일하게 진행했다. 간략하게 내용만 정리해보겠다. 자세한 명령어는 메뉴얼을 참고해라.

## 0. Pre-Installation

1. **Hostname 설정** : os-controller / os-compute / os-network / os-storage
2. **`/etc/host` 작성** : Hostname과 주소 정보 매핑  
   Horizon 대시보드에서 UI로 접근하기 위해서는 로컬 경로 `C:\Windows\System32\drivers\etc\hosts`에도 설정이 필요
3. **ulimit 상향 조정** : MariaDB의 장애를 막기 위한 사전 조치
4. (선택) **Swap 설정 변경** : 스왑 사용 X
5. **최신 OS 패키지 설치** : `sudo apt update -y && sudo apt dist-upgrade -y`
6. **NTP(Network Time Protocol) Client** : 시간 동기화를 위해 모든 서버에 `chrony` 설치
7. **OpenStack Repository 추가** : 2025.1 Epoxy 버전 설치
8. **재부팅**

## 1. Prerequisite Services

OpenStack의 기반이 되는 외부 서비스를 설치한다.

- [MariaDB](https://docs.openstack.org/install-guide/environment-sql-database-ubuntu.html) → OpenStack 서비스 설정/메타데이터 저장용 DB
- [RabbitMQ](https://docs.openstack.org/install-guide/environment-messaging-ubuntu.html) → 서비스 간 메시지 큐(비동기 통신)
- [Memcached](https://docs.openstack.org/install-guide/environment-memcached-ubuntu.html) → 인증 토큰 캐시 등 성능 향상 캐시 서버

## 2. Manual Installation

1. **(Controller) [Keystone – 인증/권한 관리](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-06-8gsmzxc9?shr=sy2e8w6dto1ywy9q3kwizv0i)**  
   1.1 Keystone DB 생성  
   1.2 Keystone 패키지 설치 및 `keystone.conf` 파일 작성  
   1.3 DB 내용 생성  
   1.4 Keystone이 동작 하기 위한 기초 설정 - Admin 계정 및 비밀번호 설정, Apache 설정, `openrc`파일로 환경 변수 저장  
   1.5 Project 생성 - Nova, Glance, Cinder 등이 사용할 운영용 Project  
   1.6 User 생성  
   1.7 Role 생성
2. **(Controller) [Glance – 이미지 관리](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-07-0-bmwoazxd?shr=f78fhn8ttgcnx5h2ob6hvbux)**  
   2.1 Glance DB 생성  
   2.2 glance라는 OpenStack 계정 생성 및 프로젝트 권한 부여  
   2.3 glance라는 Service 생성  
   2.4 Endpoint 생성  
   2.5 Glance 패키지 설치 및 `glance-api.conf` 파일 작성  
   2.6 DB 내용 생성  
   2.7 policy.yaml 작성  
   2.8 Glance-api 시작
3. **(Controller) [Placement – 컴퓨트 자원 조회/관리](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-08-0-ca5zp7l9?shr=6tejtjgyhrvuonujrf37v6pm)**  
   3.1 Placement DB 생성  
   3.2 placement라는 OpenStack 계정 생성 및 프로젝트 권한 부여  
   3.3 placement라는 Service 생성  
   3.4 Endpoint 생성  
   3.5 Placement 패키지 설치 및 `placement.conf` 파일 작성  
   3.6 DB 내용 생성  
   3.7 Apache2 재시작 (Placement는 별도의 프로세스가 아니라, Apache2에 연동되어 구동하는 Apache의 Python module이다)
4. **(Controller) [Nova – VM 생성/스케줄링 제어](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-09-0-2xunv5m2?shr=kuu10ze1rrjagxany0qjf3mh)**  
   4.1 Nova DB 생성  
   4.2 Nova라는 OpenStack 계정 생성 및 프로젝트 권한 부여  
   4.3 Nova라는 Service 생성  
   4.4 Endpoint 생성  
   4.5 Nova 패키지 설치 및 `nova.conf` 파일 작성 - nova-api / nova-conductor / nova-novncproxy / nova-scheduler  
   4.6 DB 내용 생성 - nova-api DB, cell0 DB, cell1 DB, nova DB  
   4.7 Nova service 시작
5. **(Compute) [Nova-compute](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-10-0-1vr50zoo?shr=03ub6w58sonov4s8z1kojg73)**  
   5.1 nova-compute 패키지 설치 및 `nova.conf` 파일 작성  
   5.2 `nova-compute.conf` 파일 내용 확인 - libvirt ...  
   5.3 nova-compute 서비스 시작  
   5.4 iscsid 기동  
   **(Controller)**  
   5.5 등록된 nova-compute 서비스가 있는지 확인  
   5.6 등록된 내용을 바탕으로 DB 내용 생성
6. **(Controller) [Neutron – 네트워크 구성/관리](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-11-0-ku7c8j48?shr=h10u6tmqvaa05sw86w7u9veq)**  
   6.1 Neutron DB 생성  
   6.2 Neutron이라는 OpenStack 계정 생성 및 프로젝트 권한 부여  
   6.3 Neutron이라는 Service 생성  
   6.4 Endpoint 생성  
   6.5 Neutron 패키지 설치 - ovn-central / openvswitch-common / openvswitch-switch / neutron-server  
   6.6 OVN 설정 - OVN NB/SB를 수동으로 설정하고, ovs-db의 바인딩을 열어줌  
   6.7 ovn-northd 실행  
   6.8 `neutron.conf` 파일 작성  
   6.9 `ml2.conf.ini` 파일 작성 - 실제 OVN 관련 내용  
   6.10 CTRL 노드를 Gateway Chassis로 설정 (Provider 네트워크만 생성하는 경우는 의미 없음)  
   6.11 DB 내용 생성  
   6.12 neutron-server 시작
7. **(Compute) [Neutron-compute](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-12-0-9r6cy81h?shr=tbo0kzjxf1xh4urdvm615kun)**  
   7.1 패키지 설치 - ovn-host / openvswitch-switch / neutron-ovn-metadata-agent  
   7.2 OVN 시작 및 설정 - Compute 노드의 OpenvSwitch가 Controller 노드를 바라보도록 설정  
   7.3 Geneve 통신을 할 VTEP 인터페이스 IP 설정  
   7.4 Provider 네트워크를 사용하기 위해 `br-ex` 생성하고 `phynet1`에 브리지 매핑  
   7.4 `lan1`을 `br-ex`와 연동  
   7.5 ovn-controller, neutron-ovn-metadata-agent 시작  
   7.6 OVN-Controller가 OpenvSwitch와 통신할 수 있도록 OpenvSwitch의 로컬 포트를 열어놓음  
   7.7 OpenvSwitch 설정 - netplan 적용  
   7.8 ovn-controller 재기동  
   7.9 `ml2_conf.ini` 수정  
   **(Controller)**  
   7.10 Compute 노드가 잘 추가 되었는지 확인 : `ovn-sbctl show`  
   **(Compute)**  
   7.11 `neutron_ovn_metadata_agent.ini` 파일 수정  
   7.12 neutron-ovn-metadata-agent 재기동  
   **(Controller / Compute)**  
   7.13 `nova.conf`에 Neutron과 연동하기 위한 설정 내용 추가  
   **(Controller)**  
   7.14 DB 내용 생성  
   7.15 nova-api, nova-conductor, nova-scheduler 재기동  
   **(Compute)**  
   7.16 nova-compute 재기동
8. **(Controller) [Cinder – 블록 스토리지 제공](https://smsolutions.slab.com/public/posts/open-stack-%EC%8C%A9%EC%A7%9C-%EC%84%A4%EC%B9%98-part-13-0-d3nwt9fd?shr=bhsilj8qlcp80ceh6ovxwpy1)**  
   8.1 Cinder DB 생성  
   8.2 Cinder라는 OpenStack 계정 생성 및 프로젝트 권한 부여  
   8.3 Cinder라는 Service 생성  
   8.4 Endpoint 생성  
   8.5 Cinder 패키지 설치 및 `cinder.conf` 파일 작성  
   8.6 DB 내용 생성  
   8.7 apache2, cinder-scheduler 서비스 재시작  
   **(Storage)**\_Cinder에서 VG를 가져다가 LVM 볼륨 기반의 iSCSI를 구성  
   여기서 구성하는 내용은 개발환경 수준에서 쓸 수 있는 Cinder 구성임  
   8.8 패키지 설치 - lvm2 / thin-provisioning-tools  
   8.9 디스크 초기화, PV 생성, VG 생성, `lvm.conf` 수정  
   8.10 Compute 노드에 Volume을 제공하기 위한 패키지 설치 - cinder-volume / tgt  
   8.11 `cinder.conf` 수정  
   8.12 tgtd 관련 config 수정 - `include /var/lib/cinder/volumes/*` 넣어줌  
   8.13 tgt, cinder-volume 서비스 시작  
   **(Controller)**  
   8.14 Cinder-volume이 제대로 보이는지 확인
9. **(Controller) [Horizon – 웹 대시보드 UI](https://docs.openstack.org/horizon/2025.1/install/install-ubuntu.html)**
   - 접속 URL : [controller IP]/horizon

## 3. Network 구성

Neutron을 통해 VM이 사용할 네트워크를 생성한다.

1. Provider network 생성  
   `phynet1` 스위치를 사용한 `Flat` 타입 네트워크 생성
2. 네트워크 대역대(subnet) 등록
3. 보안 그룹 생성  
   tcp, icmp, udp 모두 허용

## 4. VM 생성

1. Cinder 볼륨 연동형 VM 생성
   - 디스크는 Storage 노드에 생성되고, Compute 노드에는 CPU와 MEM만 존재하는 형태의 VM이다.
   - Glance에서 이미지를 받아와서 Storage 노드에 디스크를 만든다.
2. 로컬 디스크 VM 생성
   - VM이 생성되는 곳에 디스크를 만드는 방법이다.
   - 이 방법은 서버가 죽어버리면 VM도 같이 죽는다는 단점이 있다.
